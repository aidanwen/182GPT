{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKPK_t2l6Ck2"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook you will be implementing a Jax version of GPT from [this](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) paper. Please read it in order to better understand the model. In particular, pay attention to the applications of a pre-trained model to fine-tuning and few-shot learning.\n",
    "\n",
    "Afterwards, the notebook will walk you through several experiments using your pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WactSPHN5T0T"
   },
   "outputs": [],
   "source": [
    "# basic explanation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLUx-KxF78fd"
   },
   "outputs": [],
   "source": [
    "# jax explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-jzjm1_7GSi"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsRvOg0X8fFz",
    "outputId": "d4444bac-59e1-442b-c90c-f310df4b563f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: flax in /usr/local/lib/python3.8/dist-packages (0.6.2)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from flax) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from flax) (4.1.1)\n",
      "Requirement already satisfied: optax in /usr/local/lib/python3.8/dist-packages (from flax) (0.1.4)\n",
      "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.8/dist-packages (from flax) (0.3.25)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from flax) (6.0)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.8/dist-packages (from flax) (0.1.28)\n",
      "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.8/dist-packages (from flax) (12.6.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from flax) (3.2.2)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.16->flax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.16->flax) (1.7.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich>=11.1->flax) (2.6.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from rich>=11.1->flax) (0.9.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->flax) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from optax->flax) (1.3.0)\n",
      "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from optax->flax) (0.1.5)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax->flax) (0.3.25+cuda11.cudnn805)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax) (0.12.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wni6QpMz7IhW"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state, checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82FvhR1V9T8H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAW6RzUk14IL"
   },
   "source": [
    "# Helper Functions\n",
    "\n",
    "These are functions you may find helpful in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zB6F65HU1-V4"
   },
   "outputs": [],
   "source": [
    "class TransformerGELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies GELU function layer-wise\n",
    "    \"\"\"\n",
    "    def setup(self, approximate=False):\n",
    "        super().__init__()\n",
    "        self.approximate = approximate\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return nn.gelu(x, self.approximate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I82fHHq9VdH"
   },
   "source": [
    "# Implementation\n",
    "\n",
    "In this section you will implement x parts of the Flax/JAX GPT model. Specifically: (list what we end up deciding)\n",
    "\n",
    "\n",
    "\n",
    "You will also be coding task-specific input transformations for fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0oa1jB_1way"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNoBdcXw__w9"
   },
   "source": [
    "## (1) Implementing Attention and Multi-Headed Attention\n",
    "\n",
    "(Description of how GPT attention might differ from non-gpt attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-uMA3J39Yob"
   },
   "outputs": [],
   "source": [
    "# copy paste implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snh5sDHBAL0b"
   },
   "source": [
    "## (2) Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnu-RXXwAhWz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD7lIfccAhfw"
   },
   "source": [
    "## (3) Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz11HoQEBHGS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gN0iexDBHOm"
   },
   "source": [
    "## (4) Putting it all together: Transformer Decoder Block and GPT\n",
    "\n",
    "We have implemented the TransformerFeedForward class for you. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWi1l5VIBpIs"
   },
   "outputs": [],
   "source": [
    "# transformer decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5O_KxBY-Dw4S"
   },
   "outputs": [],
   "source": [
    "# gpt block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3buWu9yDynh"
   },
   "outputs": [],
   "source": [
    "# pretrain OR import pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jWC24WmDm1L"
   },
   "source": [
    "## (5) Task-specific Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRIi0JWfAK2f"
   },
   "outputs": [],
   "source": [
    "# import a test task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2PEHv8j-XV8"
   },
   "source": [
    "# Experiments\n",
    "\n",
    "In this section you will (train) and evaluate models with different pre-training strategies. (Note: if neccessary, we could reduce the number of parameters for this part)\n",
    "\n",
    "These models are:\n",
    "(1) No unsupervised pretraining, only fine-tuning\n",
    "(2) Pretraining on same dataset as fine-tune task\n",
    "(3) Pretraining on dataset which combines data from several tasks\n",
    "(4) Pretraining on an unrelated dataset. This pretrained model is provided.\n",
    "\n",
    "Before starting, consider how you expect these models to perform (1) on their related fine-tuning task, and (2) how well these models will generalize to other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMcZFV4jCc7c"
   },
   "outputs": [],
   "source": [
    "# import default gpt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34XkhKCbAgrQ"
   },
   "source": [
    "## Experiment 1: The value of pretraining\n",
    "\n",
    "In this section we will fine-tune a randomly initialized GPT model on (task 1). We will also fine-tune the pre-trained model on the same task. \n",
    "\n",
    "Compare the results. (Which model has better performance? Which converges faster?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKqEq2VLAJp_"
   },
   "outputs": [],
   "source": [
    "# initialize a blank GPT model\n",
    "\n",
    "# fine-tune on task 1\n",
    "\n",
    "# fine-tune pretrained model on task 1\n",
    "\n",
    "# graph results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI2oCbgUDJzB"
   },
   "source": [
    "Q: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50ODH2qgAxsO"
   },
   "source": [
    "## Experiment 2: Pretraining on related datasets\n",
    "\n",
    "In this section we will remove the labels from the (task 1) dataset, and use it to pretrain our GPT implementation. We will then fine-tune the model on (task 1) and (task 2), and evaluate the respective models. \n",
    "\n",
    "\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XJMdPbaDMVW"
   },
   "outputs": [],
   "source": [
    "# construct dataset using a subset of (task 1) labels.\n",
    "\n",
    "# pretrain a blank GPT model on this dataset OR import the weights directly\n",
    "\n",
    "# fine-tune on (task 1) \n",
    "\n",
    "# fine-tune on (task 2)\n",
    "\n",
    "# evaluate task 1 on held-out task 1 data\n",
    "\n",
    "# evaluate task 1 on task 2 data\n",
    "\n",
    "# fine-tune for both tasks using model 4 as the pretrained model\n",
    "\n",
    "# graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwEs96dkDb3t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q6pFPngDdML"
   },
   "source": [
    "Q: How did the model perform on (task 1)?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yACDKg8IFwmA"
   },
   "source": [
    "Now we will see how a model pretrained on multiple tasks performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVtVDa2SF_MV"
   },
   "outputs": [],
   "source": [
    "# pre-train using combined dataset of task 1 and 2 (model 3.1)\n",
    "\n",
    "# pre-train using combined dataste of task 1,2,3 (model 3.2)\n",
    "\n",
    "# evaluate on task 1 and task 2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TB3eHj3uGU4D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxVOP-bWGXKM"
   },
   "source": [
    "Q: How did model 3.1 perform on task 1? How about model 3.2? Explain the difference in performance.\n",
    "\n",
    "Q: "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
